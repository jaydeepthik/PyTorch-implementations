{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaydeepthik/PyTorch-implementations/blob/master/pytorch_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMiK7smb35FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UooAgX7OqdHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "47c398be-ad92-407a-b305-55489e8f90a6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Dec 26 00:45:16 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bQNsyeEFfQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.14,),(0.32,))])\n",
        "train_data = datasets.MNIST('dataset/', train=True, transform=transformation, download=True)\n",
        "test_data = datasets.MNIST('dataset/', train = False, transform=transformation, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfmyDNnOG5aE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(5*5*64, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        #x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        #x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT8kU8p6NH0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(epoch, model, data_loader):\n",
        "  for e in range(epoch):\n",
        "    for batch_idx, (data, target) in enumerate(data_loader):\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      #print(data.shape, target.shape)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      #print(output.shape, target)\n",
        "      loss = F.nll_loss(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch_idx % 1000 == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(e, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()))\n",
        "    test(model, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2vRHlpiUZnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, data_loader):\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      test_loss = 0\n",
        "      correct =0\n",
        "\n",
        "      for data, target in data_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output= model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct+=pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "      test_loss /= len(test_loader.dataset)\n",
        "      print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset))) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9mELgwLnUd4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJClx8vEYMog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "7ef5bc5c-886e-4876-fc2c-4197205197ab"
      },
      "source": [
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "fit_model(10, model, train_loader)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.307456\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.093539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0374, Accuracy: 9877/10000 (99%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.011178\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.095590\n",
            "\n",
            "Test set: Average loss: 0.0377, Accuracy: 9878/10000 (99%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.003453\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.000665\n",
            "\n",
            "Test set: Average loss: 0.0332, Accuracy: 9888/10000 (99%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.002122\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.154358\n",
            "\n",
            "Test set: Average loss: 0.0271, Accuracy: 9914/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.006946\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.000335\n",
            "\n",
            "Test set: Average loss: 0.0304, Accuracy: 9902/10000 (99%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.008311\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.049676\n",
            "\n",
            "Test set: Average loss: 0.0461, Accuracy: 9868/10000 (99%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.004309\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.005535\n",
            "\n",
            "Test set: Average loss: 0.0351, Accuracy: 9904/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000229\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.004728\n",
            "\n",
            "Test set: Average loss: 0.0333, Accuracy: 9916/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.017420\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000035\n",
            "\n",
            "Test set: Average loss: 0.0433, Accuracy: 9896/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000863\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0401, Accuracy: 9902/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mldnEaeLZDrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c2b7b893-965e-4439-fa27-95eed5966cad"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Dec 26 00:49:21 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    35W / 250W |    745MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt_AFHA_qyfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}